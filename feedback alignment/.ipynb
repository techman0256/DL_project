{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from biotorch.benchmark.run import Benchmark\n",
    "from biotorch.module.biomodule import BioModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13b8e4c5eb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size_train = 16\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback Alignment on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  60000\n",
      "Test size:  10000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=True, \n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=False, \n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "print(\"Train size: \", len(train_loader.dataset))\n",
    "print(\"Test size: \", len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN implememnted with DFA and FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an ANN model using pytorch of 3 layers with\n",
    "# 1. 784 input neurons\n",
    "# 2. 50 hidden neurons\n",
    "# 3. 10 output neurons\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module has been converted to fa mode:\n",
      "\n",
      "The layer configuration was:  {'type': 'fa', 'options': {'constrain_weights': False, 'gradient_clip': False, 'init': 'xavier'}}\n",
      "- All the 2 <class 'torch.nn.modules.linear.Linear'> layers were converted successfully.\n",
      "BioModule(\n",
      "  (module): ANN(\n",
      "    (fc1): Linear(in_features=784, out_features=50, bias=True)\n",
      "    (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# covert the ANN model to a BioModule model\n",
    "\n",
    "model = ANN()\n",
    "fa = BioModule(model, mode='fa', output_dim=10)\n",
    "print(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SGD' object has no attribute 'Adam'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[0;32m      6\u001b[0m adam \u001b[38;5;241m=\u001b[39m Adam(fa\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m lr_ \u001b[38;5;241m=\u001b[39m StepLR(\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m(fa\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m), step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m     10\u001b[0m metric_config \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay_iterations\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m,  \u001b[38;5;66;03m# Display metrics every 100 iterations\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_alignment\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,     \u001b[38;5;66;03m# Enable layer-wise alignment\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m      \u001b[38;5;66;03m# Set weight ratio for alignment regularization\u001b[39;00m\n\u001b[0;32m     15\u001b[0m }\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SGD' object has no attribute 'Adam'"
     ]
    }
   ],
   "source": [
    "from biotorch.training.trainer import Trainer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim import Adam\n",
    "\n",
    "adam = Adam(fa.parameters(), lr=0.01)\n",
    "\n",
    "lr_ = StepLR(optim.Adam(fa.parameters(), lr=0.01), step_size=0.1)\n",
    "loss = CrossEntropyLoss()\n",
    "metric_config = {\n",
    "    'top_k': 5,\n",
    "    'display_iterations': 100,  # Display metrics every 100 iterations\n",
    "    'layer_alignment': False,     # Enable layer-wise alignment\n",
    "    'weight_ratio': False      # Set weight ratio for alignment regularization\n",
    "}\n",
    "\n",
    "\n",
    "trainer = Trainer(model=fa, mode='dfa', loss_function=loss, optimizer=adam, train_dataloader=train_loader, val_dataloader=test_loader, device='cpu', epochs=3, output_dir='./output', lr_scheduler=lr_, metrics_config=metric_config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/938]\tTime  0.031 ( 0.031)\tData  0.012 ( 0.012)\tLoss nan (nan)\tAcc@1   4.69 (  4.69)\tAcc@5  50.00 ( 50.00)\n",
      "Epoch: [0][100/938]\tTime  0.015 ( 0.025)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 (  9.38)\tAcc@5  46.88 ( 49.77)\n",
      "Epoch: [0][200/938]\tTime  0.017 ( 0.024)\tData  0.004 ( 0.006)\tLoss nan (nan)\tAcc@1   3.12 (  9.40)\tAcc@5  57.81 ( 50.07)\n",
      "Epoch: [0][300/938]\tTime  0.025 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.62)\tAcc@5  56.25 ( 50.30)\n",
      "Epoch: [0][400/938]\tTime  0.021 ( 0.023)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   6.25 (  9.62)\tAcc@5  53.12 ( 50.60)\n",
      "Epoch: [0][500/938]\tTime  0.028 ( 0.024)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  14.06 (  9.62)\tAcc@5  46.88 ( 50.51)\n",
      "Epoch: [0][600/938]\tTime  0.018 ( 0.024)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  14.06 (  9.63)\tAcc@5  45.31 ( 50.69)\n",
      "Epoch: [0][700/938]\tTime  0.017 ( 0.024)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   6.25 (  9.79)\tAcc@5  39.06 ( 50.72)\n",
      "Epoch: [0][800/938]\tTime  0.019 ( 0.024)\tData  0.004 ( 0.006)\tLoss nan (nan)\tAcc@1  12.50 (  9.84)\tAcc@5  56.25 ( 50.88)\n",
      "Epoch: [0][900/938]\tTime  0.029 ( 0.024)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 (  9.85)\tAcc@5  57.81 ( 50.98)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "New best accuracy reached: 9.800000190734863 \n",
      "Saving best accuracy model...\n",
      "Epoch: [1][  0/938]\tTime  0.057 ( 0.057)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   9.38 (  9.38)\tAcc@5  53.12 ( 53.12)\n",
      "Epoch: [1][100/938]\tTime  0.022 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 ( 10.26)\tAcc@5  45.31 ( 52.29)\n",
      "Epoch: [1][200/938]\tTime  0.043 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 ( 10.23)\tAcc@5  45.31 ( 51.76)\n",
      "Epoch: [1][300/938]\tTime  0.020 ( 0.024)\tData  0.007 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 ( 10.26)\tAcc@5  62.50 ( 51.46)\n",
      "Epoch: [1][400/938]\tTime  0.034 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 ( 10.08)\tAcc@5  43.75 ( 51.20)\n",
      "Epoch: [1][500/938]\tTime  0.022 ( 0.024)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.86)\tAcc@5  40.62 ( 51.02)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\biotorch\\training\\trainer.py:74\u001b[0m, in \u001b[0;36mTrainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_weight_ratio(epoch)\n\u001b[0;32m     73\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 74\u001b[0m acc, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_iterations\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy/train\u001b[39m\u001b[38;5;124m'\u001b[39m, acc, epoch)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss/train\u001b[39m\u001b[38;5;124m'\u001b[39m, loss, epoch)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\biotorch\\training\\functions.py:31\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, mode, loss_function, optimizer, train_dataloader, device, epoch, multi_gpu, top_k, display_iterations)\u001b[0m\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     30\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 31\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Measure data loading time\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Send inputs to device\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\functional.py:175\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    173\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# resize MNIST images to 32x32\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)), transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[0;32m      3\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m      4\u001b[0m   torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m                              transform\u001b[38;5;241m=\u001b[39mtransform),\n\u001b[0;32m      6\u001b[0m   batch_size\u001b[38;5;241m=\u001b[39mbatch_size_train, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m      9\u001b[0m     torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mMNIST(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m                                  transform\u001b[38;5;241m=\u001b[39mtransform),\n\u001b[0;32m     11\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size_test, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# resize MNIST images to 32x32\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor()])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                             transform=transform),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data', train=False, download=True,\n",
    "                                 transform=transform),\n",
    "    batch_size=batch_size_test, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module has been converted to dfa mode:\n",
      "\n",
      "The layer configuration was:  {'type': 'dfa', 'options': {'constrain_weights': False, 'init': 'xavier', 'gradient_clip': False}}\n",
      "- All the 3 <class 'torch.nn.modules.conv.Conv2d'> layers were converted successfully.\n",
      "- All the 2 <class 'torch.nn.modules.linear.Linear'> layers were converted successfully.\n",
      "BioModule(\n",
      "  (module): LeNet(\n",
      "    (conv1): Conv2d(1, 6, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (relu1): ReLU()\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): Conv2d(6, 16, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (relu2): ReLU()\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv3): Conv2d(16, 120, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (relu3): ReLU()\n",
      "    (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (relu4): ReLU()\n",
      "    (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create a lenet model using pytorch\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    # def __init__(self):\n",
    "    #     super(LeNet, self).__init__()\n",
    "    #     self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "    #     self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "    #     self.fc1 = nn.Linear(4*4*50, 500)\n",
    "    #     self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     x = F.relu(self.conv1(x))\n",
    "    #     x = F.max_pool2d(x, 2, 2)\n",
    "    #     x = F.relu(self.conv2(x))\n",
    "    #     x = F.max_pool2d(x, 2, 2)\n",
    "    #     x = x.view(-1, 4*4*50)\n",
    "    #     x = F.relu(self.fc1(x))\n",
    "    #     x = self.fc2(x)\n",
    "    #     return F.log_softmax(x, dim=1)\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=4, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=4, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=4, stride=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "lenet = LeNet()\n",
    "\n",
    "# convert the LeNet model to a BioModule model\n",
    "\n",
    "# model = LeNet()\n",
    "alex = BioModule(lenet, mode='dfa', output_dim=10)\n",
    "print(alex)\n",
    "# adam = Adam(alex.parameters(), lr=0.01)\n",
    "from torch.optim import SGD\n",
    "optim = SGD(alex.parameters(), lr=0.01, momentum=0.9, weight_decay=10e-3)\n",
    "\n",
    "\n",
    "lr_ = StepLR(adam, step_size=0.1)\n",
    "loss = CrossEntropyLoss()\n",
    "metric_config = {\n",
    "    'top_k': 5,\n",
    "    'display_iterations': 100,  # Display metrics every 100 iterations\n",
    "    'layer_alignment': False,     # Enable layer-wise alignment\n",
    "    'weight_ratio': False      # Set weight ratio for alignment regularization\n",
    "}\n",
    "\n",
    "\n",
    "trainer = Trainer(model=alex, mode='dfa', loss_function=loss, optimizer=optim, train_dataloader=train_loader, val_dataloader=test_loader, device='cpu', epochs=100, output_dir='./output', lr_scheduler=lr_, metrics_config=metric_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/938]\tTime  0.036 ( 0.036)\tData  0.013 ( 0.013)\tLoss 2.3121e+00 (2.3121e+00)\tAcc@1   7.81 (  7.81)\tAcc@5  42.19 ( 42.19)\n",
      "Epoch: [0][100/938]\tTime  0.039 ( 0.027)\tData  0.005 ( 0.006)\tLoss 2.2642e+27 (1.3521e+26)\tAcc@1  14.06 ( 10.26)\tAcc@5  56.25 ( 50.74)\n",
      "Epoch: [0][200/938]\tTime  0.018 ( 0.025)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   4.69 ( 10.11)\tAcc@5  46.88 ( 50.52)\n",
      "Epoch: [0][300/938]\tTime  0.018 ( 0.024)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  12.50 ( 10.01)\tAcc@5  56.25 ( 50.64)\n",
      "Epoch: [0][400/938]\tTime  0.020 ( 0.047)\tData  0.007 ( 0.008)\tLoss nan (nan)\tAcc@1  10.94 ( 10.05)\tAcc@5  56.25 ( 50.60)\n",
      "Epoch: [0][500/938]\tTime  0.022 ( 0.043)\tData  0.005 ( 0.008)\tLoss nan (nan)\tAcc@1  12.50 ( 10.00)\tAcc@5  43.75 ( 50.71)\n",
      "Epoch: [0][600/938]\tTime  0.020 ( 0.039)\tData  0.005 ( 0.007)\tLoss nan (nan)\tAcc@1   7.81 (  9.93)\tAcc@5  56.25 ( 50.54)\n",
      "Epoch: [0][700/938]\tTime  0.018 ( 0.037)\tData  0.004 ( 0.007)\tLoss nan (nan)\tAcc@1   9.38 (  9.86)\tAcc@5  46.88 ( 50.54)\n",
      "Epoch: [0][800/938]\tTime  0.020 ( 0.035)\tData  0.006 ( 0.007)\tLoss nan (nan)\tAcc@1  10.94 (  9.91)\tAcc@5  50.00 ( 50.62)\n",
      "Epoch: [0][900/938]\tTime  0.028 ( 0.033)\tData  0.005 ( 0.007)\tLoss nan (nan)\tAcc@1   4.69 (  9.96)\tAcc@5  51.56 ( 50.85)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "New best accuracy reached: 9.800000190734863 \n",
      "Saving best accuracy model...\n",
      "Epoch: [1][  0/938]\tTime  0.048 ( 0.048)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 (  7.81)\tAcc@5  43.75 ( 43.75)\n",
      "Epoch: [1][100/938]\tTime  0.016 ( 0.022)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   9.38 (  9.85)\tAcc@5  48.44 ( 49.49)\n",
      "Epoch: [1][200/938]\tTime  0.021 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.83)\tAcc@5  50.00 ( 50.42)\n",
      "Epoch: [1][300/938]\tTime  0.029 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.88)\tAcc@5  51.56 ( 50.91)\n",
      "Epoch: [1][400/938]\tTime  0.018 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.93)\tAcc@5  42.19 ( 50.84)\n",
      "Epoch: [1][500/938]\tTime  0.020 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.96)\tAcc@5  48.44 ( 50.90)\n",
      "Epoch: [1][600/938]\tTime  0.019 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 ( 10.00)\tAcc@5  53.12 ( 51.19)\n",
      "Epoch: [1][700/938]\tTime  0.018 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  15.62 (  9.95)\tAcc@5  60.94 ( 51.09)\n",
      "Epoch: [1][800/938]\tTime  0.016 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.87)\tAcc@5  53.12 ( 51.04)\n",
      "Epoch: [1][900/938]\tTime  0.030 ( 0.024)\tData  0.007 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.86)\tAcc@5  45.31 ( 50.95)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [2][  0/938]\tTime  0.043 ( 0.043)\tData  0.008 ( 0.008)\tLoss nan (nan)\tAcc@1  14.06 ( 14.06)\tAcc@5  54.69 ( 54.69)\n",
      "Epoch: [2][100/938]\tTime  0.030 ( 0.026)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   0.00 ( 10.44)\tAcc@5  39.06 ( 51.95)\n",
      "Epoch: [2][200/938]\tTime  0.016 ( 0.025)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   3.12 ( 10.13)\tAcc@5  45.31 ( 51.11)\n",
      "Epoch: [2][300/938]\tTime  0.027 ( 0.025)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 (  9.93)\tAcc@5  57.81 ( 51.17)\n",
      "Epoch: [2][400/938]\tTime  0.029 ( 0.025)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   6.25 (  9.88)\tAcc@5  48.44 ( 51.14)\n",
      "Epoch: [2][500/938]\tTime  0.036 ( 0.025)\tData  0.007 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 (  9.84)\tAcc@5  40.62 ( 51.03)\n",
      "Epoch: [2][600/938]\tTime  0.019 ( 0.024)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   9.38 (  9.81)\tAcc@5  46.88 ( 51.12)\n",
      "Epoch: [2][700/938]\tTime  0.017 ( 0.024)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  14.06 (  9.86)\tAcc@5  54.69 ( 51.11)\n",
      "Epoch: [2][800/938]\tTime  0.029 ( 0.025)\tData  0.004 ( 0.006)\tLoss nan (nan)\tAcc@1   9.38 (  9.90)\tAcc@5  46.88 ( 51.12)\n",
      "Epoch: [2][900/938]\tTime  0.030 ( 0.025)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   6.25 (  9.85)\tAcc@5  48.44 ( 51.02)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [3][  0/938]\tTime  0.053 ( 0.053)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   9.38 (  9.38)\tAcc@5  54.69 ( 54.69)\n",
      "Epoch: [3][100/938]\tTime  0.052 ( 0.025)\tData  0.034 ( 0.006)\tLoss nan (nan)\tAcc@1   4.69 (  9.41)\tAcc@5  51.56 ( 51.07)\n",
      "Epoch: [3][200/938]\tTime  0.021 ( 0.024)\tData  0.006 ( 0.007)\tLoss nan (nan)\tAcc@1  10.94 (  9.39)\tAcc@5  46.88 ( 50.66)\n",
      "Epoch: [3][300/938]\tTime  0.019 ( 0.024)\tData  0.006 ( 0.007)\tLoss nan (nan)\tAcc@1  10.94 (  9.67)\tAcc@5  50.00 ( 50.91)\n",
      "Epoch: [3][400/938]\tTime  0.021 ( 0.023)\tData  0.005 ( 0.007)\tLoss nan (nan)\tAcc@1  12.50 (  9.86)\tAcc@5  62.50 ( 51.13)\n",
      "Epoch: [3][500/938]\tTime  0.018 ( 0.023)\tData  0.005 ( 0.007)\tLoss nan (nan)\tAcc@1  10.94 (  9.79)\tAcc@5  50.00 ( 51.10)\n",
      "Epoch: [3][600/938]\tTime  0.017 ( 0.023)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 (  9.75)\tAcc@5  56.25 ( 51.27)\n",
      "Epoch: [3][700/938]\tTime  0.021 ( 0.023)\tData  0.008 ( 0.006)\tLoss nan (nan)\tAcc@1   9.38 (  9.81)\tAcc@5  45.31 ( 51.26)\n",
      "Epoch: [3][800/938]\tTime  0.035 ( 0.023)\tData  0.017 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 (  9.85)\tAcc@5  43.75 ( 51.12)\n",
      "Epoch: [3][900/938]\tTime  0.017 ( 0.023)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  15.62 (  9.86)\tAcc@5  54.69 ( 51.09)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [4][  0/938]\tTime  0.021 ( 0.021)\tData  0.007 ( 0.007)\tLoss nan (nan)\tAcc@1   6.25 (  6.25)\tAcc@5  57.81 ( 57.81)\n",
      "Epoch: [4][100/938]\tTime  0.016 ( 0.021)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   6.25 (  9.82)\tAcc@5  54.69 ( 51.28)\n",
      "Epoch: [4][200/938]\tTime  0.019 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.93)\tAcc@5  37.50 ( 51.37)\n",
      "Epoch: [4][300/938]\tTime  0.019 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 ( 10.06)\tAcc@5  48.44 ( 51.08)\n",
      "Epoch: [4][400/938]\tTime  0.015 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.92)\tAcc@5  46.88 ( 50.89)\n",
      "Epoch: [4][500/938]\tTime  0.017 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.81)\tAcc@5  53.12 ( 50.85)\n",
      "Epoch: [4][600/938]\tTime  0.025 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.84)\tAcc@5  43.75 ( 50.96)\n",
      "Epoch: [4][700/938]\tTime  0.015 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.87)\tAcc@5  46.88 ( 50.97)\n",
      "Epoch: [4][800/938]\tTime  0.035 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.92)\tAcc@5  50.00 ( 51.02)\n",
      "Epoch: [4][900/938]\tTime  0.019 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.86)\tAcc@5  53.12 ( 50.97)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [5][  0/938]\tTime  0.033 ( 0.033)\tData  0.007 ( 0.007)\tLoss nan (nan)\tAcc@1   9.38 (  9.38)\tAcc@5  51.56 ( 51.56)\n",
      "Epoch: [5][100/938]\tTime  0.021 ( 0.021)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1  18.75 (  9.79)\tAcc@5  53.12 ( 51.04)\n",
      "Epoch: [5][200/938]\tTime  0.019 ( 0.021)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 ( 10.00)\tAcc@5  45.31 ( 51.46)\n",
      "Epoch: [5][300/938]\tTime  0.021 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   1.56 (  9.79)\tAcc@5  51.56 ( 51.37)\n",
      "Epoch: [5][400/938]\tTime  0.027 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.82)\tAcc@5  51.56 ( 51.12)\n",
      "Epoch: [5][500/938]\tTime  0.020 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.70)\tAcc@5  57.81 ( 50.97)\n",
      "Epoch: [5][600/938]\tTime  0.026 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  15.62 (  9.82)\tAcc@5  54.69 ( 51.18)\n",
      "Epoch: [5][700/938]\tTime  0.024 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.78)\tAcc@5  60.94 ( 51.09)\n",
      "Epoch: [5][800/938]\tTime  0.018 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.85)\tAcc@5  54.69 ( 51.09)\n",
      "Epoch: [5][900/938]\tTime  0.020 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.84)\tAcc@5  46.88 ( 51.00)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [6][  0/938]\tTime  0.054 ( 0.054)\tData  0.008 ( 0.008)\tLoss nan (nan)\tAcc@1  15.62 ( 15.62)\tAcc@5  62.50 ( 62.50)\n",
      "Epoch: [6][100/938]\tTime  0.027 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.55)\tAcc@5  53.12 ( 50.94)\n",
      "Epoch: [6][200/938]\tTime  0.015 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.84)\tAcc@5  56.25 ( 50.93)\n",
      "Epoch: [6][300/938]\tTime  0.025 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  17.19 (  9.98)\tAcc@5  43.75 ( 50.83)\n",
      "Epoch: [6][400/938]\tTime  0.016 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.86)\tAcc@5  48.44 ( 50.72)\n",
      "Epoch: [6][500/938]\tTime  0.028 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.82)\tAcc@5  42.19 ( 50.92)\n",
      "Epoch: [6][600/938]\tTime  0.030 ( 0.022)\tData  0.003 ( 0.005)\tLoss nan (nan)\tAcc@1  15.62 (  9.83)\tAcc@5  48.44 ( 51.06)\n",
      "Epoch: [6][700/938]\tTime  0.014 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.78)\tAcc@5  53.12 ( 51.08)\n",
      "Epoch: [6][800/938]\tTime  0.026 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.86)\tAcc@5  50.00 ( 51.09)\n",
      "Epoch: [6][900/938]\tTime  0.018 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.83)\tAcc@5  51.56 ( 50.93)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [7][  0/938]\tTime  0.082 ( 0.082)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   1.56 (  1.56)\tAcc@5  50.00 ( 50.00)\n",
      "Epoch: [7][100/938]\tTime  0.019 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.62)\tAcc@5  42.19 ( 50.82)\n",
      "Epoch: [7][200/938]\tTime  0.022 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.65)\tAcc@5  53.12 ( 50.78)\n",
      "Epoch: [7][300/938]\tTime  0.021 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.61)\tAcc@5  62.50 ( 50.81)\n",
      "Epoch: [7][400/938]\tTime  0.016 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  15.62 (  9.75)\tAcc@5  54.69 ( 50.73)\n",
      "Epoch: [7][500/938]\tTime  0.035 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.80)\tAcc@5  46.88 ( 50.90)\n",
      "Epoch: [7][600/938]\tTime  0.024 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1  15.62 (  9.96)\tAcc@5  56.25 ( 51.05)\n",
      "Epoch: [7][700/938]\tTime  0.018 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  14.06 (  9.89)\tAcc@5  53.12 ( 50.99)\n",
      "Epoch: [7][800/938]\tTime  0.032 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.90)\tAcc@5  43.75 ( 50.98)\n",
      "Epoch: [7][900/938]\tTime  0.031 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  14.06 (  9.88)\tAcc@5  59.38 ( 50.95)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [8][  0/938]\tTime  0.084 ( 0.084)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  12.50 ( 12.50)\tAcc@5  57.81 ( 57.81)\n",
      "Epoch: [8][100/938]\tTime  0.017 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 ( 10.75)\tAcc@5  56.25 ( 52.07)\n",
      "Epoch: [8][200/938]\tTime  0.018 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 ( 10.18)\tAcc@5  48.44 ( 51.96)\n",
      "Epoch: [8][300/938]\tTime  0.027 ( 0.024)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 ( 10.11)\tAcc@5  51.56 ( 51.87)\n",
      "Epoch: [8][400/938]\tTime  0.021 ( 0.024)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 ( 10.13)\tAcc@5  64.06 ( 51.73)\n",
      "Epoch: [8][500/938]\tTime  0.020 ( 0.024)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 ( 10.03)\tAcc@5  53.12 ( 51.45)\n",
      "Epoch: [8][600/938]\tTime  0.015 ( 0.023)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 ( 10.05)\tAcc@5  53.12 ( 51.37)\n",
      "Epoch: [8][700/938]\tTime  0.020 ( 0.023)\tData  0.007 ( 0.006)\tLoss nan (nan)\tAcc@1  12.50 (  9.99)\tAcc@5  56.25 ( 51.37)\n",
      "Epoch: [8][800/938]\tTime  0.016 ( 0.023)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  12.50 (  9.92)\tAcc@5  53.12 ( 51.08)\n",
      "Epoch: [8][900/938]\tTime  0.019 ( 0.023)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 (  9.88)\tAcc@5  50.00 ( 51.05)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [9][  0/938]\tTime  0.024 ( 0.024)\tData  0.008 ( 0.008)\tLoss nan (nan)\tAcc@1   9.38 (  9.38)\tAcc@5  57.81 ( 57.81)\n",
      "Epoch: [9][100/938]\tTime  0.038 ( 0.025)\tData  0.007 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 (  9.65)\tAcc@5  48.44 ( 51.13)\n",
      "Epoch: [9][200/938]\tTime  0.062 ( 0.025)\tData  0.007 ( 0.006)\tLoss nan (nan)\tAcc@1  14.06 (  9.90)\tAcc@5  65.62 ( 50.69)\n",
      "Epoch: [9][300/938]\tTime  0.015 ( 0.024)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  12.50 (  9.87)\tAcc@5  53.12 ( 50.79)\n",
      "Epoch: [9][400/938]\tTime  0.113 ( 0.031)\tData  0.019 ( 0.006)\tLoss nan (nan)\tAcc@1  12.50 (  9.78)\tAcc@5  51.56 ( 50.89)\n",
      "Epoch: [9][500/938]\tTime  0.125 ( 0.056)\tData  0.015 ( 0.008)\tLoss nan (nan)\tAcc@1  12.50 (  9.90)\tAcc@5  51.56 ( 51.05)\n",
      "Epoch: [9][600/938]\tTime  0.025 ( 0.057)\tData  0.005 ( 0.008)\tLoss nan (nan)\tAcc@1  21.88 (  9.93)\tAcc@5  62.50 ( 51.16)\n",
      "Epoch: [9][700/938]\tTime  0.033 ( 0.052)\tData  0.010 ( 0.008)\tLoss nan (nan)\tAcc@1   7.81 (  9.89)\tAcc@5  43.75 ( 51.12)\n",
      "Epoch: [9][800/938]\tTime  0.024 ( 0.048)\tData  0.006 ( 0.008)\tLoss nan (nan)\tAcc@1   3.12 (  9.86)\tAcc@5  45.31 ( 51.05)\n",
      "Epoch: [9][900/938]\tTime  0.020 ( 0.045)\tData  0.005 ( 0.007)\tLoss nan (nan)\tAcc@1   3.12 (  9.88)\tAcc@5  46.88 ( 51.05)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [10][  0/938]\tTime  0.048 ( 0.048)\tData  0.007 ( 0.007)\tLoss nan (nan)\tAcc@1   9.38 (  9.38)\tAcc@5  57.81 ( 57.81)\n",
      "Epoch: [10][100/938]\tTime  0.019 ( 0.022)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   1.56 (  9.96)\tAcc@5  34.38 ( 51.02)\n",
      "Epoch: [10][200/938]\tTime  0.151 ( 0.036)\tData  0.013 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 (  9.99)\tAcc@5  50.00 ( 50.58)\n",
      "Epoch: [10][300/938]\tTime  0.035 ( 0.069)\tData  0.005 ( 0.008)\tLoss nan (nan)\tAcc@1  10.94 (  9.93)\tAcc@5  53.12 ( 50.84)\n",
      "Epoch: [10][400/938]\tTime  0.018 ( 0.059)\tData  0.006 ( 0.008)\tLoss nan (nan)\tAcc@1  10.94 ( 10.07)\tAcc@5  51.56 ( 51.23)\n",
      "Epoch: [10][500/938]\tTime  0.021 ( 0.051)\tData  0.004 ( 0.007)\tLoss nan (nan)\tAcc@1  10.94 ( 10.03)\tAcc@5  56.25 ( 51.16)\n",
      "Epoch: [10][600/938]\tTime  0.015 ( 0.046)\tData  0.005 ( 0.007)\tLoss nan (nan)\tAcc@1  15.62 (  9.96)\tAcc@5  45.31 ( 51.14)\n",
      "Epoch: [10][700/938]\tTime  0.031 ( 0.043)\tData  0.006 ( 0.007)\tLoss nan (nan)\tAcc@1   7.81 (  9.98)\tAcc@5  46.88 ( 51.04)\n",
      "Epoch: [10][800/938]\tTime  0.019 ( 0.040)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 (  9.89)\tAcc@5  45.31 ( 51.07)\n",
      "Epoch: [10][900/938]\tTime  0.020 ( 0.038)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  12.50 (  9.89)\tAcc@5  51.56 ( 51.04)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [11][  0/938]\tTime  0.055 ( 0.055)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 ( 10.94)\tAcc@5  46.88 ( 46.88)\n",
      "Epoch: [11][100/938]\tTime  0.065 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 ( 10.10)\tAcc@5  45.31 ( 51.07)\n",
      "Epoch: [11][200/938]\tTime  0.023 ( 0.025)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 ( 10.35)\tAcc@5  53.12 ( 51.24)\n",
      "Epoch: [11][300/938]\tTime  0.026 ( 0.025)\tData  0.007 ( 0.005)\tLoss nan (nan)\tAcc@1  15.62 ( 10.15)\tAcc@5  51.56 ( 51.55)\n",
      "Epoch: [11][400/938]\tTime  0.026 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 ( 10.19)\tAcc@5  62.50 ( 51.45)\n",
      "Epoch: [11][500/938]\tTime  0.026 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 ( 10.13)\tAcc@5  50.00 ( 51.47)\n",
      "Epoch: [11][600/938]\tTime  0.019 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.94)\tAcc@5  57.81 ( 51.27)\n",
      "Epoch: [11][700/938]\tTime  0.020 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  17.19 (  9.91)\tAcc@5  51.56 ( 51.17)\n",
      "Epoch: [11][800/938]\tTime  0.031 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1   3.12 (  9.91)\tAcc@5  50.00 ( 51.19)\n",
      "Epoch: [11][900/938]\tTime  0.032 ( 0.023)\tData  0.006 ( 0.005)\tLoss nan (nan)\tAcc@1   3.12 (  9.90)\tAcc@5  46.88 ( 51.06)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [12][  0/938]\tTime  0.075 ( 0.075)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 ( 10.94)\tAcc@5  46.88 ( 46.88)\n",
      "Epoch: [12][100/938]\tTime  0.018 ( 0.023)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   4.69 (  9.87)\tAcc@5  37.50 ( 50.43)\n",
      "Epoch: [12][200/938]\tTime  0.015 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.89)\tAcc@5  37.50 ( 50.66)\n",
      "Epoch: [12][300/938]\tTime  0.035 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.88)\tAcc@5  51.56 ( 50.97)\n",
      "Epoch: [12][400/938]\tTime  0.019 ( 0.024)\tData  0.007 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.89)\tAcc@5  50.00 ( 50.72)\n",
      "Epoch: [12][500/938]\tTime  0.019 ( 0.034)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1  17.19 (  9.95)\tAcc@5  56.25 ( 50.94)\n",
      "Epoch: [12][600/938]\tTime  0.019 ( 0.032)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   4.69 (  9.86)\tAcc@5  48.44 ( 51.02)\n",
      "Epoch: [12][700/938]\tTime  0.015 ( 0.031)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 (  9.85)\tAcc@5  43.75 ( 50.94)\n",
      "Epoch: [12][800/938]\tTime  0.015 ( 0.030)\tData  0.004 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 (  9.79)\tAcc@5  37.50 ( 50.90)\n",
      "Epoch: [12][900/938]\tTime  0.034 ( 0.029)\tData  0.004 ( 0.006)\tLoss nan (nan)\tAcc@1   9.38 (  9.86)\tAcc@5  53.12 ( 50.96)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [13][  0/938]\tTime  0.089 ( 0.089)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  10.94 ( 10.94)\tAcc@5  51.56 ( 51.56)\n",
      "Epoch: [13][100/938]\tTime  0.036 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.58)\tAcc@5  53.12 ( 51.18)\n",
      "Epoch: [13][200/938]\tTime  0.019 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.57)\tAcc@5  45.31 ( 51.04)\n",
      "Epoch: [13][300/938]\tTime  0.020 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  17.19 (  9.89)\tAcc@5  43.75 ( 51.21)\n",
      "Epoch: [13][400/938]\tTime  0.016 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.90)\tAcc@5  48.44 ( 51.11)\n",
      "Epoch: [13][500/938]\tTime  0.020 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.66)\tAcc@5  43.75 ( 50.92)\n",
      "Epoch: [13][600/938]\tTime  0.015 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.70)\tAcc@5  64.06 ( 51.16)\n",
      "Epoch: [13][700/938]\tTime  0.019 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.71)\tAcc@5  48.44 ( 51.05)\n",
      "Epoch: [13][800/938]\tTime  0.015 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.77)\tAcc@5  43.75 ( 50.99)\n",
      "Epoch: [13][900/938]\tTime  0.017 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.82)\tAcc@5  46.88 ( 51.05)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [14][  0/938]\tTime  0.082 ( 0.082)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1   3.12 (  3.12)\tAcc@5  46.88 ( 46.88)\n",
      "Epoch: [14][100/938]\tTime  0.033 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.48)\tAcc@5  45.31 ( 50.48)\n",
      "Epoch: [14][200/938]\tTime  0.016 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.61)\tAcc@5  43.75 ( 50.41)\n",
      "Epoch: [14][300/938]\tTime  0.030 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.84)\tAcc@5  54.69 ( 50.80)\n",
      "Epoch: [14][400/938]\tTime  0.022 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.78)\tAcc@5  57.81 ( 50.89)\n",
      "Epoch: [14][500/938]\tTime  0.027 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.74)\tAcc@5  48.44 ( 50.68)\n",
      "Epoch: [14][600/938]\tTime  0.018 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.73)\tAcc@5  45.31 ( 50.83)\n",
      "Epoch: [14][700/938]\tTime  0.019 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.78)\tAcc@5  53.12 ( 50.90)\n",
      "Epoch: [14][800/938]\tTime  0.017 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  17.19 (  9.92)\tAcc@5  53.12 ( 51.07)\n",
      "Epoch: [14][900/938]\tTime  0.018 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.91)\tAcc@5  54.69 ( 50.99)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [15][  0/938]\tTime  0.080 ( 0.080)\tData  0.006 ( 0.006)\tLoss nan (nan)\tAcc@1  17.19 ( 17.19)\tAcc@5  57.81 ( 57.81)\n",
      "Epoch: [15][100/938]\tTime  0.018 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 ( 10.15)\tAcc@5  50.00 ( 51.25)\n",
      "Epoch: [15][200/938]\tTime  0.015 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.96)\tAcc@5  53.12 ( 50.64)\n",
      "Epoch: [15][300/938]\tTime  0.027 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.77)\tAcc@5  62.50 ( 50.56)\n",
      "Epoch: [15][400/938]\tTime  0.023 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.84)\tAcc@5  45.31 ( 50.93)\n",
      "Epoch: [15][500/938]\tTime  0.018 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.81)\tAcc@5  50.00 ( 51.05)\n",
      "Epoch: [15][600/938]\tTime  0.015 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.94)\tAcc@5  48.44 ( 51.01)\n",
      "Epoch: [15][700/938]\tTime  0.032 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.96)\tAcc@5  54.69 ( 51.02)\n",
      "Epoch: [15][800/938]\tTime  0.019 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.91)\tAcc@5  53.12 ( 51.04)\n",
      "Epoch: [15][900/938]\tTime  0.033 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.90)\tAcc@5  51.56 ( 51.05)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [16][  0/938]\tTime  0.046 ( 0.046)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  7.81)\tAcc@5  45.31 ( 45.31)\n",
      "Epoch: [16][100/938]\tTime  0.023 ( 0.021)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 ( 10.12)\tAcc@5  53.12 ( 51.01)\n",
      "Epoch: [16][200/938]\tTime  0.019 ( 0.021)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.77)\tAcc@5  42.19 ( 51.06)\n",
      "Epoch: [16][300/938]\tTime  0.032 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.74)\tAcc@5  54.69 ( 51.08)\n",
      "Epoch: [16][400/938]\tTime  0.019 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  14.06 (  9.73)\tAcc@5  48.44 ( 51.02)\n",
      "Epoch: [16][500/938]\tTime  0.020 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   1.56 (  9.75)\tAcc@5  40.62 ( 50.92)\n",
      "Epoch: [16][600/938]\tTime  0.016 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.82)\tAcc@5  50.00 ( 50.93)\n",
      "Epoch: [16][700/938]\tTime  0.016 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.83)\tAcc@5  51.56 ( 50.91)\n",
      "Epoch: [16][800/938]\tTime  0.019 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.95)\tAcc@5  56.25 ( 51.10)\n",
      "Epoch: [16][900/938]\tTime  0.018 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   4.69 (  9.89)\tAcc@5  48.44 ( 51.03)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [17][  0/938]\tTime  0.096 ( 0.096)\tData  0.007 ( 0.007)\tLoss nan (nan)\tAcc@1  12.50 ( 12.50)\tAcc@5  57.81 ( 57.81)\n",
      "Epoch: [17][100/938]\tTime  0.029 ( 0.026)\tData  0.005 ( 0.006)\tLoss nan (nan)\tAcc@1   1.56 (  9.56)\tAcc@5  50.00 ( 50.79)\n",
      "Epoch: [17][200/938]\tTime  0.023 ( 0.026)\tData  0.007 ( 0.006)\tLoss nan (nan)\tAcc@1   7.81 (  9.68)\tAcc@5  56.25 ( 51.26)\n",
      "Epoch: [17][300/938]\tTime  0.140 ( 0.047)\tData  0.017 ( 0.008)\tLoss nan (nan)\tAcc@1  12.50 (  9.81)\tAcc@5  57.81 ( 51.02)\n",
      "Epoch: [17][400/938]\tTime  0.180 ( 0.084)\tData  0.015 ( 0.009)\tLoss nan (nan)\tAcc@1  12.50 (  9.93)\tAcc@5  60.94 ( 51.07)\n",
      "Epoch: [17][500/938]\tTime  0.029 ( 0.087)\tData  0.005 ( 0.009)\tLoss nan (nan)\tAcc@1  14.06 (  9.93)\tAcc@5  53.12 ( 51.11)\n",
      "Epoch: [17][600/938]\tTime  0.016 ( 0.076)\tData  0.004 ( 0.009)\tLoss nan (nan)\tAcc@1  15.62 (  9.99)\tAcc@5  53.12 ( 51.09)\n",
      "Epoch: [17][700/938]\tTime  0.034 ( 0.068)\tData  0.004 ( 0.008)\tLoss nan (nan)\tAcc@1  20.31 (  9.95)\tAcc@5  57.81 ( 50.97)\n",
      "Epoch: [17][800/938]\tTime  0.022 ( 0.063)\tData  0.005 ( 0.008)\tLoss nan (nan)\tAcc@1  12.50 (  9.87)\tAcc@5  57.81 ( 50.94)\n",
      "Epoch: [17][900/938]\tTime  0.020 ( 0.058)\tData  0.005 ( 0.007)\tLoss nan (nan)\tAcc@1   7.81 (  9.83)\tAcc@5  50.00 ( 50.98)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [18][  0/938]\tTime  0.055 ( 0.055)\tData  0.007 ( 0.007)\tLoss nan (nan)\tAcc@1   9.38 (  9.38)\tAcc@5  39.06 ( 39.06)\n",
      "Epoch: [18][100/938]\tTime  0.027 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  17.19 (  9.00)\tAcc@5  50.00 ( 49.69)\n",
      "Epoch: [18][200/938]\tTime  0.032 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.77)\tAcc@5  53.12 ( 50.47)\n",
      "Epoch: [18][300/938]\tTime  0.030 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 ( 10.03)\tAcc@5  59.38 ( 50.62)\n",
      "Epoch: [18][400/938]\tTime  0.017 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.90)\tAcc@5  43.75 ( 50.92)\n",
      "Epoch: [18][500/938]\tTime  0.027 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   3.12 (  9.96)\tAcc@5  56.25 ( 51.02)\n",
      "Epoch: [18][600/938]\tTime  0.030 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  17.19 ( 10.00)\tAcc@5  62.50 ( 51.01)\n",
      "Epoch: [18][700/938]\tTime  0.015 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  15.62 (  9.90)\tAcc@5  51.56 ( 50.98)\n",
      "Epoch: [18][800/938]\tTime  0.021 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 (  9.89)\tAcc@5  51.56 ( 51.00)\n",
      "Epoch: [18][900/938]\tTime  0.021 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.88)\tAcc@5  59.38 ( 50.97)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [19][  0/938]\tTime  0.089 ( 0.089)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  10.94 ( 10.94)\tAcc@5  59.38 ( 59.38)\n",
      "Epoch: [19][100/938]\tTime  0.017 ( 0.022)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 ( 10.10)\tAcc@5  50.00 ( 51.16)\n",
      "Epoch: [19][200/938]\tTime  0.034 ( 0.022)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 (  9.93)\tAcc@5  48.44 ( 51.57)\n",
      "Epoch: [19][300/938]\tTime  0.030 ( 0.023)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 ( 10.06)\tAcc@5  57.81 ( 51.27)\n",
      "Epoch: [19][400/938]\tTime  0.027 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  17.19 ( 10.05)\tAcc@5  45.31 ( 50.68)\n",
      "Epoch: [19][500/938]\tTime  0.036 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1  12.50 (  9.90)\tAcc@5  53.12 ( 50.84)\n",
      "Epoch: [19][600/938]\tTime  0.045 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.90)\tAcc@5  54.69 ( 50.87)\n",
      "Epoch: [19][700/938]\tTime  0.021 ( 0.024)\tData  0.004 ( 0.005)\tLoss nan (nan)\tAcc@1   6.25 (  9.89)\tAcc@5  50.00 ( 50.95)\n",
      "Epoch: [19][800/938]\tTime  0.033 ( 0.024)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   0.00 (  9.87)\tAcc@5  54.69 ( 50.91)\n",
      "Epoch: [19][900/938]\tTime  0.021 ( 0.023)\tData  0.005 ( 0.005)\tLoss nan (nan)\tAcc@1   9.38 (  9.85)\tAcc@5  45.31 ( 50.95)\n",
      " * Acc@1 9.800 Acc@5 51.390\n",
      "Epoch: [20][  0/938]\tTime  0.048 ( 0.048)\tData  0.007 ( 0.007)\tLoss nan (nan)\tAcc@1   9.38 (  9.38)\tAcc@5  48.44 ( 48.44)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\biotorch\\training\\trainer.py:74\u001b[0m, in \u001b[0;36mTrainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_weight_ratio(epoch)\n\u001b[0;32m     73\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 74\u001b[0m acc, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_iterations\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy/train\u001b[39m\u001b[38;5;124m'\u001b[39m, acc, epoch)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss/train\u001b[39m\u001b[38;5;124m'\u001b[39m, loss, epoch)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\biotorch\\training\\functions.py:31\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, mode, loss_function, optimizer, train_dataloader, device, epoch, multi_gpu, top_k, display_iterations)\u001b[0m\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     30\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 31\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Measure data loading time\u001b[39;49;00m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Send inputs to device\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\functional.py:173\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    171\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 97.970 Acc@1 97.970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(97.9700), 64.33413543701172)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from biotorch.training.functions import test\n",
    "\n",
    "test(alex, loss, test_loader, device='cpu', top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a CNN model using pytorch of 3 cnn layers with with 2 fully connected layers\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
    "        self.fc1 = nn.Linear(2*2*128, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 2*2*128)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module has been converted to dfa mode:\n",
      "\n",
      "The layer configuration was:  {'type': 'dfa', 'options': {'constrain_weights': False, 'init': 'xavier', 'gradient_clip': False}}\n",
      "- All the 3 <class 'torch.nn.modules.conv.Conv2d'> layers were converted successfully.\n",
      "- All the 2 <class 'torch.nn.modules.linear.Linear'> layers were converted successfully.\n",
      "BioModule(\n",
      "  (module): CNN(\n",
      "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "# convert the CNN model to a BioModule model\n",
    "model = BioModule(model, mode='dfa', output_dim=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biotorch.training.trainer import Trainer\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "adam = Adam(model.parameters(), lr=0.01)\n",
    "lr_ = StepLR(adam, step_size=0.1)\n",
    "loss = CrossEntropyLoss()\n",
    "\n",
    "metric_config = {\n",
    "    'top_k': 5,\n",
    "    'display_iterations': 100,  # Display metrics every 100 iterations\n",
    "    'layer_alignment': False,     # Enable layer-wise alignment\n",
    "    'weight_ratio': False      # Set weight ratio for alignment regularization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, mode='dfa', loss_function=loss, optimizer=adam, train_dataloader=train_loader, val_dataloader=test_loader, device='cpu', epochs=100, output_dir='./output', lr_scheduler=lr_, metrics_config=metric_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (16) to match target batch_size (64).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\biotorch\\training\\trainer.py:74\u001b[0m, in \u001b[0;36mTrainer.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_weight_ratio(epoch)\n\u001b[0;32m     73\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 74\u001b[0m acc, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay_iterations\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy/train\u001b[39m\u001b[38;5;124m'\u001b[39m, acc, epoch)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss/train\u001b[39m\u001b[38;5;124m'\u001b[39m, loss, epoch)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\biotorch\\training\\functions.py:38\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, mode, loss_function, optimizer, train_dataloader, device, epoch, multi_gpu, top_k, display_iterations)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Get outputs from the model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdfa\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\biotorch\\module\\biomodule.py:32\u001b[0m, in \u001b[0;36mBioModule.forward\u001b[1;34m(self, x, targets, loss_function)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou need to introduce your `loss_function` for Direct Feedback Alignment mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m loss_gradient \u001b[38;5;241m=\u001b[39m grad(loss, output, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Broadcast gradient of the loss to every layer\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (16) to match target batch_size (64)."
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
