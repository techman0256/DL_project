{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "from biotorch.benchmark.run import Benchmark\n",
    "from biotorch.module.biomodule import BioModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2357f657d90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = Net()\n",
    "# network = BioModule(network, mode='fa')\n",
    "print(network)\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      # torch.save(network.state_dict(), '/results/model.pth')\n",
    "      # torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patel\\AppData\\Local\\Temp\\ipykernel_29740\\161431047.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.2953, Accuracy: 841/10000 (8%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.286329\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.269986\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.265898\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.297638\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.244451\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.259844\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.188649\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.192837\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.154733\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.910791\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.878963\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.910301\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.669419\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.535789\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.568959\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.511087\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.100953\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.242976\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.011507\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.311187\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.032148\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.923839\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.723343\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.431575\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.880159\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.016228\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.833130\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.825631\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.838513\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.697748\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.918813\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.797749\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.880527\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.824198\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.815567\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.881572\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.914453\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.503055\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.727683\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.791868\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.701201\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.784908\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.698608\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.551509\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.625888\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.802527\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.768210\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.571274\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.884439\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.921040\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.797370\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.722561\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.708182\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.855901\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.693060\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.733939\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.626381\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.573269\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.776975\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.633834\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.525467\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.789465\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.664341\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.572094\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.524700\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.703414\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.605862\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.485942\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.470133\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.736443\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.446898\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.550950\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.542792\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.596334\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.602388\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.568114\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.584250\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.623058\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.592839\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.493464\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.478549\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.436639\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.718237\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.579520\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.440262\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.763649\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.312972\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.381280\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.440663\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.546159\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.513002\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.389841\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.714932\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.753187\n",
      "\n",
      "Test set: Avg. loss: 0.2152, Accuracy: 9378/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.661429\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.361178\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.384491\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.419002\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.485528\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.416724\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.536882\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.279656\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.496730\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.513875\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.503068\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.446614\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.679195\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.461276\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.390143\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.709822\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.403366\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.512911\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.303490\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.500139\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.379826\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.588638\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.463002\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.471956\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.207144\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.365900\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.421828\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.530884\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.365993\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.499598\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.416230\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.363467\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.256643\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.527251\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.347121\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.288728\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.597403\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.467612\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.208683\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.370299\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.434536\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.420987\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.410314\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.439135\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.348548\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.435349\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.395425\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.305068\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.188396\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.312938\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.357602\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.372483\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.297074\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.370044\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.473200\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.430840\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.373646\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.395978\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.261175\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.626301\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.579529\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.359658\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.517161\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.230150\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.597901\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.570263\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.431814\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.237685\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.286853\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.413981\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.442547\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.338159\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.595967\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.381525\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.388078\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.533458\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.332137\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.234713\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.331623\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.297293\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.545250\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.304498\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.330520\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.274364\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.389967\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.173255\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.370197\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.758261\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.449358\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.327600\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.257415\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.289332\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.263063\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.279285\n",
      "\n",
      "Test set: Avg. loss: 0.1303, Accuracy: 9591/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.190995\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.432185\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.350992\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.289225\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.366197\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.289057\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.367288\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.184861\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.251184\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.328030\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.202009\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.258581\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.464542\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.377038\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.240584\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.306168\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.435819\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.369899\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.253361\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.673529\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.233187\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.489862\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.355484\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.360476\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.476847\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.363349\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.374238\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.442678\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.560912\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.450185\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.232629\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.341054\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.401259\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.242140\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.366139\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.306841\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.168179\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.183941\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.334995\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.267844\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.223908\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.393479\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.408902\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.599688\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.300067\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.223203\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.374761\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.247374\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.434488\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.232243\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.434365\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.300193\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.280778\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.368745\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.245985\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.594016\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.285925\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.236806\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.363009\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.263348\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.299566\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.252858\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.323670\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.358772\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.353170\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.384584\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.399412\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.209410\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.351704\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.409492\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.210731\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.432490\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.213206\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.126070\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.365655\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.314802\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.240826\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.272952\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.250314\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.187131\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.269015\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.229216\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.247051\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.393938\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.240422\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.436426\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.219797\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.483854\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.450801\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.336989\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.120877\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.279797\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.151320\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.308309\n",
      "\n",
      "Test set: Avg. loss: 0.0995, Accuracy: 9671/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "#         self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.fc = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.pool1(self.relu1(self.conv1(x)))\n",
    "#         out = self.pool2(self.relu2(self.conv2(out)))\n",
    "#         out = self.relu3(self.conv3(out))\n",
    "#         out = F.avg_pool2d(out, out.size()[3])\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
